# ====================================================================
# æ‚¨çš„äº’å‹•å¼è¼¿æƒ…åˆ†æç¶²ç«™
# æª”æ¡ˆåç¨±: app.py
# ====================================================================

import streamlit as st
import requests
from bs4 import BeautifulSoup
import jieba
from wordcloud import WordCloud
import matplotlib.pyplot as plt
import plotly.graph_objects as go

# --- æ ¸å¿ƒåŠŸèƒ½å‡½æ•¸ ---

# 1. æŠ“å–Googleæœå°‹çµæœçš„ç¶²é æ¨™é¡Œ
def scrape_google_titles(query, num_pages=1):
    """æ ¹æ“šé—œéµå­—ï¼ŒæŠ“å–Googleæœå°‹çµæœçš„æ¨™é¡Œã€‚"""
    st.info(f"ğŸ” æ­£åœ¨æœå°‹é—œæ–¼ã€Œ{query}ã€çš„ç¶²è·¯è³‡è¨Š...")
    all_titles = ""
    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'}
    
    for page in range(num_pages):
        url = f"https://www.google.com/search?q={query}&start={page*10}"
        try:
            response = requests.get(url, headers=headers)
            response.raise_for_status() # ç¢ºä¿è«‹æ±‚æˆåŠŸ
            soup = BeautifulSoup(response.text, 'html.parser')
            # æ‰¾åˆ°æ‰€æœ‰ h3 æ¨™ç±¤ï¼Œé€™é€šå¸¸æ˜¯æœå°‹çµæœçš„æ¨™é¡Œ
            titles = soup.find_all('h3')
            for title in titles:
                all_titles += title.get_text() + " "
        except requests.exceptions.RequestException as e:
            st.error(f"æŠ“å–å¤±æ•—: {e}")
            return "" # æŠ“å–å¤±æ•—æ™‚è¿”å›ç©ºå­—ä¸²
            
    st.success("âœ… è³‡è¨ŠæŠ“å–å®Œæˆï¼")
    return all_titles

# 2. ç”¢ç”Ÿæ–‡å­—é›²
def generate_wordcloud(text):
    """æ ¹æ“šæ–‡æœ¬ç”¢ç”Ÿæ–‡å­—é›²åœ–ç‰‡ã€‚"""
    st.info("â˜ï¸ æ­£åœ¨ç”Ÿæˆæ–‡å­—é›²...")
    # ä½¿ç”¨ jieba é€²è¡Œä¸­æ–‡åˆ†è©
    word_list = jieba.cut(text)
    words = " ".join(word_list)

    # è¨­å®šä¸­æ–‡å­—é«”è·¯å¾‘ (è«‹æ ¹æ“šæ‚¨çš„ä½œæ¥­ç³»çµ±èª¿æ•´)
    # Windows: C:/Windows/Fonts/msjh.ttc (å¾®è»Ÿæ­£é»‘é«”)
    # Mac: /System/Library/Fonts/PingFang.ttc (è˜‹æ–¹)
    # å¦‚æœè·¯å¾‘éŒ¯èª¤ï¼Œæ–‡å­—é›²æœƒé¡¯ç¤ºç‚ºæ–¹å¡Š
    font_path = 'C:/Windows/Fonts/msjh.ttc' 

    try:
        wordcloud = WordCloud(width=800, 
                              height=400, 
                              background_color='white', 
                              font_path=font_path,
                              collocations=False # é¿å…é‡è¤‡è©
                             ).generate(words)
    except RuntimeError:
         st.error("æ‰¾ä¸åˆ°ä¸­æ–‡å­—é«”ï¼è«‹ç¢ºèª `font_path` çš„è·¯å¾‘æ˜¯å¦æ­£ç¢ºã€‚")
         return None


    # ä½¿ç”¨ matplotlib é¡¯ç¤ºåœ–ç‰‡
    fig, ax = plt.subplots(figsize=(10, 5))
    ax.imshow(wordcloud, interpolation='bilinear')
    ax.axis('off')
    st.pyplot(fig)
    st.success("âœ… æ–‡å­—é›²ç”Ÿæˆå®Œç•¢ï¼")


# 3. ç”¢ç”Ÿæƒ…ç·’åˆ†æåœ–è¡¨ (æ­¤è™•ç‚ºç¯„ä¾‹)
def generate_sentiment_chart():
    """ç”¢ç”Ÿä¸€å€‹ç¯„ä¾‹çš„äº’å‹•å¼åœ“é¤…åœ–ã€‚"""
    st.info("ğŸ“Š æ­£åœ¨ç”Ÿæˆäº’å‹•å¼åœ–è¡¨...")
    labels = ['æ­£é¢/æœŸå¾…', 'ä¸­æ€§/è³‡è¨Š', 'è² é¢/æŠ±æ€¨']
    values = [60, 35, 5] # ç¯„ä¾‹æ•¸æ“š

    fig = go.Figure(data=[go.Pie(labels=labels, values=values, hole=.3)])
    fig.update_layout(title_text="<b>ç¶²è·¯è¼¿æƒ…æƒ…ç·’åˆ†ä½ˆ (ç¯„ä¾‹)</b>")
    st.plotly_chart(fig)
    st.success("âœ… äº’å‹•å¼åœ–è¡¨ç”Ÿæˆå®Œç•¢ï¼")

# --- ç¶²ç«™ä»‹é¢è¨­è¨ˆ ---

# è¨­å®šç¶²é æ¨™é¡Œå’Œåœ–ç¤º
st.set_page_config(page_title="äº’å‹•å¼è¼¿æƒ…åˆ†æå„€", page_icon="ğŸ“ˆ")

# ç¶²ç«™æ¨™é¡Œ
st.title("ğŸ“ˆ äº’å‹•å¼ç¶²è·¯è¼¿æƒ…åˆ†æå„€")
st.write("é€™æ˜¯ä¸€å€‹ç°¡æ˜“çš„ç¶²è·¯è¼¿æƒ…åˆ†æå·¥å…·ï¼Œæ‚¨å¯ä»¥è¼¸å…¥ä»»ä½•é—œéµå­—ï¼Œå®ƒæœƒè‡ªå‹•æŠ“å–ç›¸é—œè³‡è¨Šä¸¦ç”Ÿæˆè¦–è¦ºåŒ–çš„æ–‡å­—é›²èˆ‡åœ–è¡¨ã€‚")

# è®“ä½¿ç”¨è€…è¼¸å…¥é—œéµå­—
query = st.text_input("è«‹è¼¸å…¥æ‚¨æƒ³åˆ†æçš„é—œéµå­—ï¼ˆä¾‹å¦‚ï¼šé£Ÿå°šç©å®¶ï¼‰", "é£Ÿå°šç©å®¶")

# åˆ†ææŒ‰éˆ•
if st.button("ğŸš€ é–‹å§‹åˆ†æï¼"):
    if query:
        # æ­¥é©Ÿ 1: æŠ“å–è³‡æ–™
        scraped_text = scrape_google_titles(query)
        
        if scraped_text:
            # é¡¯ç¤ºæŠ“å–åˆ°çš„åŸå§‹æ–‡å­—æ‘˜è¦
            with st.expander("é»æ­¤æŸ¥çœ‹æŠ“å–åˆ°çš„æ–‡å­—æ‘˜è¦"):
                st.write(scraped_text)
                
            # æ­¥é©Ÿ 2: ç”¢ç”Ÿæ–‡å­—é›²
            generate_wordcloud(scraped_text)
            
            # æ­¥é©Ÿ 3: ç”¢ç”Ÿäº’å‹•åœ–è¡¨
            generate_sentiment_chart()

    else:
        st.warning("è«‹å…ˆè¼¸å…¥é—œéµå­—ï¼")

st.markdown("---")
st.write("ç”± Gemini AI å”åŠ©é–‹ç™¼")